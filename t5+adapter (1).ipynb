{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yzkS7FVCPxa"
      },
      "source": [
        "with adapter + t5 decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNV6t61JGfZv"
      },
      "source": [
        "### mount gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlFIq2zSCcrx",
        "outputId": "f0038b8c-9d0f-475b-bf59-349bb6af47aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq17nt0ACxOY"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPJO_Mx3QRJ9"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/rna-binding')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17A_zUAVCvK1",
        "outputId": "d8d1459a-4860-4dc1-df43-bbcd31fe9158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy-xGj78GIBo"
      },
      "source": [
        "### data prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ176Aj0etVV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7Hl_M7zeVnA"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('final_attract_db_with_emb.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6AMmpLfAr5x"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "# Load the dictionary back from the pickle file.\n",
        "with open(\"rbp_seqs_dict.pkl\", \"rb\") as f:\n",
        "    rbp_seqs_dict = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOBIK9NqBmux"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rna_motif_emb = np.load('rna_motif_emb.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR5oupoyDg0_",
        "outputId": "34175395-09e2-4456-f0f9-14cdb5fe66db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "len(rna_motif_emb[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XlC-0ezvDnxN"
      },
      "outputs": [],
      "source": [
        "data = data.drop(columns=['rna_motif_emb', 'rbp_esm_emb'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "476-y3RlEQGe"
      },
      "outputs": [],
      "source": [
        "data['rna_motif_emb'] = rna_motif_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ek95MlFMEoTp"
      },
      "outputs": [],
      "source": [
        "data['rbp_esm_emb'] = data['RBP_sequence'].map(rbp_seqs_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r45nc1dZEuPy"
      },
      "outputs": [],
      "source": [
        "# Convert list of tensors to numpy array\n",
        "def tensors_to_numpy(tensor_list):\n",
        "    return np.stack([t.numpy() for t in tensor_list])\n",
        "\n",
        "# Apply the conversion to the 'rbp_esm_emb' column\n",
        "data['rbp_esm_emb'] = data['rbp_esm_emb'].apply(tensors_to_numpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xY37cMdeFAlM",
        "outputId": "c3f73149-30d2-4378-f7cd-626a191204d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Gene_name          Gene_id        Motif  \\\n",
              "0         A1CF  ENSG00000148584  UGAUCAGUAUA   \n",
              "1         A1CF  ENSG00000148584      AUAAUUA   \n",
              "2         A1CF  ENSG00000148584      UUAAUUA   \n",
              "3         A1CF  ENSG00000148584      AUAAUUG   \n",
              "4         A1CF  ENSG00000148584      UUAAUUG   \n",
              "...        ...              ...          ...   \n",
              "3247     SRSF1  ENSG00000136450      CGGCGGU   \n",
              "3248     SRSF2  ENSG00000161547    GAAAGGAGA   \n",
              "3249   HNRNPAB  ENSG00000197451       AUAGCA   \n",
              "3250   HNRNPA1  ENSG00000135486         UAGG   \n",
              "3251     PTBP1  ENSG00000011304       UUCUUC   \n",
              "\n",
              "                                           RBP_sequence  \\\n",
              "0     MESNHKSGDGLSGTQKEAALRALVQRTGYSLVQENGQRKYGGPPPG...   \n",
              "1     MESNHKSGDGLSGTQKEAALRALVQRTGYSLVQENGQRKYGGPPPG...   \n",
              "2     MESNHKSGDGLSGTQKEAALRALVQRTGYSLVQENGQRKYGGPPPG...   \n",
              "3     MESNHKSGDGLSGTQKEAALRALVQRTGYSLVQENGQRKYGGPPPG...   \n",
              "4     MESNHKSGDGLSGTQKEAALRALVQRTGYSLVQENGQRKYGGPPPG...   \n",
              "...                                                 ...   \n",
              "3247  MSGGGVIRGPAGNNDCRIYVGNLPPDIRTKDIEDVFYKYGAIRDID...   \n",
              "3248  MSYGRPPPDVEGMTSLKVDNLTYRTSPDTLRRVFEKYGRVGDVYIP...   \n",
              "3249  MSEAGEEQPMETTGATENGHEAVPEASRGRGWTGAAAGAGGATAAP...   \n",
              "3250  MSKSESPKEPEQLRKLFIGGLSFETTDESLRSHFEQWGTLTDCVVM...   \n",
              "3251  MDGIVPDIAVGTKRGSDELFSTCVTNGPFIMSSNSASAANGNDSKK...   \n",
              "\n",
              "                                          rna_motif_emb  \\\n",
              "0     [[0.02515462040901184, -0.1693081259727478, 1....   \n",
              "1     [[-0.005481339991092682, -0.008752591907978058...   \n",
              "2     [[-0.006157027557492256, -0.04564734920859337,...   \n",
              "3     [[0.0016195997595787048, 0.0697508156299591, 1...   \n",
              "4     [[0.02757852151989937, 0.006868686527013779, 3...   \n",
              "...                                                 ...   \n",
              "3247  [[0.03172174096107483, -0.21967869997024536, -...   \n",
              "3248  [[0.013123728334903717, -0.012446027249097824,...   \n",
              "3249  [[-0.0034322012215852737, 0.000896155834197998...   \n",
              "3250  [[0.11391925066709518, -0.08793018758296967, 7...   \n",
              "3251  [[-0.05293735861778259, -0.0894496887922287, 2...   \n",
              "\n",
              "                                            rbp_esm_emb  \n",
              "0     [[0.102689214, -0.18220823, -0.05008613, 0.156...  \n",
              "1     [[0.102689214, -0.18220823, -0.05008613, 0.156...  \n",
              "2     [[0.102689214, -0.18220823, -0.05008613, 0.156...  \n",
              "3     [[0.102689214, -0.18220823, -0.05008613, 0.156...  \n",
              "4     [[0.102689214, -0.18220823, -0.05008613, 0.156...  \n",
              "...                                                 ...  \n",
              "3247  [[0.19127601, -0.11130471, 0.0977051, 0.116294...  \n",
              "3248  [[0.26023224, -0.14764462, 0.03352632, 0.18112...  \n",
              "3249  [[0.019191047, 0.034460854, 0.13640618, 0.1387...  \n",
              "3250  [[0.14509255, -0.06513151, -0.03306822, 0.0129...  \n",
              "3251  [[0.099172145, 0.026364552, -0.02337196, 0.139...  \n",
              "\n",
              "[3252 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16538f23-9886-4592-a64b-4197a1165473\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gene_name</th>\n",
              "      <th>Gene_id</th>\n",
              "      <th>Motif</th>\n",
              "      <th>RBP_sequence</th>\n",
              "      <th>rna_motif_emb</th>\n",
              "      <th>rbp_esm_emb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A1CF</td>\n",
              "      <td>ENSG00000148584</td>\n",
              "      <td>UGAUCAGUAUA</td>\n",
              "      <td>MESNHKSGDGLSGTQKEAALRALVQRTGYSLVQENGQRKYGGPPPG...</td>\n",
              "      <td>[[0.02515462040901184, -0.1693081259727478, 1....</td>\n",
              "      <td>[[0.102689214, -0.18220823, -0.05008613, 0.156...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A1CF</td>\n",
              "      <td>ENSG00000148584</td>\n",
              "      <td>AUAAUUA</td>\n",
              "      <td>MESNHKSGDGLSGTQKEAALRALVQRTGYSLVQENGQRKYGGPPPG...</td>\n",
              "      <td>[[-0.005481339991092682, -0.008752591907978058...</td>\n",
              "      <td>[[0.102689214, -0.18220823, -0.05008613, 0.156...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A1CF</td>\n",
              "      <td>ENSG00000148584</td>\n",
              "      <td>UUAAUUA</td>\n",
              "      <td>MESNHKSGDGLSGTQKEAALRALVQRTGYSLVQENGQRKYGGPPPG...</td>\n",
              "      <td>[[-0.006157027557492256, -0.04564734920859337,...</td>\n",
              "      <td>[[0.102689214, -0.18220823, -0.05008613, 0.156...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A1CF</td>\n",
              "      <td>ENSG00000148584</td>\n",
              "      <td>AUAAUUG</td>\n",
              "      <td>MESNHKSGDGLSGTQKEAALRALVQRTGYSLVQENGQRKYGGPPPG...</td>\n",
              "      <td>[[0.0016195997595787048, 0.0697508156299591, 1...</td>\n",
              "      <td>[[0.102689214, -0.18220823, -0.05008613, 0.156...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A1CF</td>\n",
              "      <td>ENSG00000148584</td>\n",
              "      <td>UUAAUUG</td>\n",
              "      <td>MESNHKSGDGLSGTQKEAALRALVQRTGYSLVQENGQRKYGGPPPG...</td>\n",
              "      <td>[[0.02757852151989937, 0.006868686527013779, 3...</td>\n",
              "      <td>[[0.102689214, -0.18220823, -0.05008613, 0.156...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3247</th>\n",
              "      <td>SRSF1</td>\n",
              "      <td>ENSG00000136450</td>\n",
              "      <td>CGGCGGU</td>\n",
              "      <td>MSGGGVIRGPAGNNDCRIYVGNLPPDIRTKDIEDVFYKYGAIRDID...</td>\n",
              "      <td>[[0.03172174096107483, -0.21967869997024536, -...</td>\n",
              "      <td>[[0.19127601, -0.11130471, 0.0977051, 0.116294...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3248</th>\n",
              "      <td>SRSF2</td>\n",
              "      <td>ENSG00000161547</td>\n",
              "      <td>GAAAGGAGA</td>\n",
              "      <td>MSYGRPPPDVEGMTSLKVDNLTYRTSPDTLRRVFEKYGRVGDVYIP...</td>\n",
              "      <td>[[0.013123728334903717, -0.012446027249097824,...</td>\n",
              "      <td>[[0.26023224, -0.14764462, 0.03352632, 0.18112...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3249</th>\n",
              "      <td>HNRNPAB</td>\n",
              "      <td>ENSG00000197451</td>\n",
              "      <td>AUAGCA</td>\n",
              "      <td>MSEAGEEQPMETTGATENGHEAVPEASRGRGWTGAAAGAGGATAAP...</td>\n",
              "      <td>[[-0.0034322012215852737, 0.000896155834197998...</td>\n",
              "      <td>[[0.019191047, 0.034460854, 0.13640618, 0.1387...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3250</th>\n",
              "      <td>HNRNPA1</td>\n",
              "      <td>ENSG00000135486</td>\n",
              "      <td>UAGG</td>\n",
              "      <td>MSKSESPKEPEQLRKLFIGGLSFETTDESLRSHFEQWGTLTDCVVM...</td>\n",
              "      <td>[[0.11391925066709518, -0.08793018758296967, 7...</td>\n",
              "      <td>[[0.14509255, -0.06513151, -0.03306822, 0.0129...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3251</th>\n",
              "      <td>PTBP1</td>\n",
              "      <td>ENSG00000011304</td>\n",
              "      <td>UUCUUC</td>\n",
              "      <td>MDGIVPDIAVGTKRGSDELFSTCVTNGPFIMSSNSASAANGNDSKK...</td>\n",
              "      <td>[[-0.05293735861778259, -0.0894496887922287, 2...</td>\n",
              "      <td>[[0.099172145, 0.026364552, -0.02337196, 0.139...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3252 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16538f23-9886-4592-a64b-4197a1165473')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16538f23-9886-4592-a64b-4197a1165473 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16538f23-9886-4592-a64b-4197a1165473');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bda70bb3-9c19-46fa-a3d5-700019852e05\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bda70bb3-9c19-46fa-a3d5-700019852e05')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bda70bb3-9c19-46fa-a3d5-700019852e05 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e9ab2da2-704c-4fdc-93e9-53a2cc333f4e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e9ab2da2-704c-4fdc-93e9-53a2cc333f4e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te0Kq4SNMybz",
        "outputId": "1443582a-e78f-4b5d-a3db-d88bf92780f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average length of RBP_sequence: 415.5270602706027\n"
          ]
        }
      ],
      "source": [
        "average_length = data['RBP_sequence'].apply(len).mean()\n",
        "print(f\"Average length of RBP_sequence: {average_length}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26Md0NQyNSjs"
      },
      "outputs": [],
      "source": [
        "# data = data[data['RBP_sequence'].apply(len) <= 600]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjoYW453NTg7",
        "outputId": "3db6bb39-f5e0-42ad-c800-97241c1f14ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average length of RBP_sequence: 415.5270602706027\n"
          ]
        }
      ],
      "source": [
        "average_length = data['RBP_sequence'].apply(len).mean()\n",
        "print(f\"Average length of RBP_sequence: {average_length}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEPzFUtoQguE",
        "outputId": "17f2686b-2b13-477f-aad0-c0ad2cf21d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum RBP sequence length: 2542\n",
            "Maximum Motif length: 12\n"
          ]
        }
      ],
      "source": [
        "max_rbp_sequence_length = data['RBP_sequence'].apply(len).max()\n",
        "max_motif_length = data['Motif'].apply(len).max()\n",
        "\n",
        "print(f\"Maximum RBP sequence length: {max_rbp_sequence_length}\")\n",
        "print(f\"Maximum Motif length: {max_motif_length}\")\n",
        "\n",
        "# Use these lengths for padding\n",
        "max_encoder_seq_length = max_motif_length\n",
        "max_decoder_seq_length = max_rbp_sequence_length"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Assuming meta4k is a DataFrame and 'sequence' is the column with sequence strings\n",
        "# Calculate sequence lengths\n",
        "data['sequence_length'] = data['RBP_sequence'].apply(len)\n",
        "\n",
        "# Compute Z-scores of the lengths\n",
        "data['z_scores'] = stats.zscore(data['sequence_length'])\n",
        "\n",
        "# Filter the outliers; this will keep only the rows that are not outliers\n",
        "filtered_data = data[(data['z_scores'] > -3) & (data['z_scores'] < 3)]\n",
        "\n",
        "# Determine the outliers\n",
        "outliers = data[(data['z_scores'] <= -3) | (data['z_scores'] >= 3)]\n",
        "\n",
        "# Print the outliers\n",
        "print(outliers)\n"
      ],
      "metadata": {
        "id": "GAtrr0XEEH9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29073606-5227-497f-d835-b9a869f40e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Gene_name          Gene_id         Motif  \\\n",
            "9         ADAR  ENSG00000160710          GCGC   \n",
            "10        ADAR  ENSG00000160710         GCGCG   \n",
            "16      ANKHD1  ENSG00000131503       AGACGAA   \n",
            "17      ANKHD1  ENSG00000131503       AGACGUA   \n",
            "18      ANKHD1  ENSG00000131503       AGACGAU   \n",
            "19      ANKHD1  ENSG00000131503       AGACGUU   \n",
            "117       DHX9  ENSG00000135829          CGCG   \n",
            "118       DHX9  ENSG00000135829          GCGC   \n",
            "119       DHX9  ENSG00000135829         GCGCG   \n",
            "1409     PPRC1  ENSG00000148840       CCGCGCC   \n",
            "1410     PPRC1  ENSG00000148840       GCGCGCC   \n",
            "1411     PPRC1  ENSG00000148840       CGGCGCC   \n",
            "1412     PPRC1  ENSG00000148840       GGGCGCC   \n",
            "1413     PPRC1  ENSG00000148840       CCGCGCG   \n",
            "1414     PPRC1  ENSG00000148840       GCGCGCG   \n",
            "1415     PPRC1  ENSG00000148840       CGGCGCG   \n",
            "1416     PPRC1  ENSG00000148840       GGGCGCG   \n",
            "1539      PUM1  ENSG00000134644  AAUUGUACAUAA   \n",
            "1540      PUM1  ENSG00000134644   CCAGAAUUGUA   \n",
            "1541      PUM1  ENSG00000134644   CUUGUAGAUAA   \n",
            "1542      PUM1  ENSG00000134644      UGUAAAUA   \n",
            "1543      PUM1  ENSG00000134644     UGUAAUAUU   \n",
            "1544      PUM1  ENSG00000134644       UGUACAU   \n",
            "1545      PUM1  ENSG00000134644      UGUACAUA   \n",
            "1546      PUM1  ENSG00000134644      UGUACAUC   \n",
            "1547      PUM1  ENSG00000134644      UGUAGAUA   \n",
            "1548      PUM1  ENSG00000134644      UGUAAAUA   \n",
            "1549      PUM1  ENSG00000134644      UGUAUAUA   \n",
            "1550      PUM1  ENSG00000134644      UGUACAUA   \n",
            "1551      PUM1  ENSG00000134644      UGUAAAUA   \n",
            "1552      PUM1  ENSG00000134644      UGUAUAUA   \n",
            "1553      PUM1  ENSG00000134644      UGUACAUA   \n",
            "1554      PUM1  ENSG00000134644       UGUAUAU   \n",
            "1555      PUM1  ENSG00000134644      UGUAUAUA   \n",
            "1556      PUM1  ENSG00000134644       UGUCCAG   \n",
            "1557      PUM1  ENSG00000134644     UUUAAUGUU   \n",
            "1706      RBM6  ENSG00000004534       AAUCCAA   \n",
            "1707      RBM6  ENSG00000004534       UAUCCAA   \n",
            "1708      RBM6  ENSG00000004534       CAUCCAA   \n",
            "1709      RBM6  ENSG00000004534       AAUCCAG   \n",
            "1710      RBM6  ENSG00000004534       UAUCCAG   \n",
            "1711      RBM6  ENSG00000004534       CAUCCAG   \n",
            "1750     RC3H1  ENSG00000135870     CCUUCUGUG   \n",
            "1751     RC3H1  ENSG00000135870   UCCCUUCUGUG   \n",
            "1752     RC3H1  ENSG00000135870          UUUC   \n",
            "2853      XPO5  ENSG00000124571          CCGC   \n",
            "2854      XPO5  ENSG00000124571          GUUU   \n",
            "3002    ZNF638  ENSG00000075292       CGUUCGU   \n",
            "3003    ZNF638  ENSG00000075292       UGUUCGU   \n",
            "3004    ZNF638  ENSG00000075292       GGUUCGU   \n",
            "3005    ZNF638  ENSG00000075292       CGUUGGU   \n",
            "3006    ZNF638  ENSG00000075292       UGUUGGU   \n",
            "3007    ZNF638  ENSG00000075292       GGUUGGU   \n",
            "3008    ZNF638  ENSG00000075292       CGUUCUU   \n",
            "3009    ZNF638  ENSG00000075292       UGUUCUU   \n",
            "3010    ZNF638  ENSG00000075292       GGUUCUU   \n",
            "3011    ZNF638  ENSG00000075292       CGUUGUU   \n",
            "3012    ZNF638  ENSG00000075292       UGUUGUU   \n",
            "3013    ZNF638  ENSG00000075292       GGUUGUU   \n",
            "\n",
            "                                           RBP_sequence  \\\n",
            "9     MNPRQGYSLSGYYTHPFQGYEHRQLRYQQPGPGSSPSSFLLKQIEF...   \n",
            "10    MNPRQGYSLSGYYTHPFQGYEHRQLRYQQPGPGSSPSSFLLKQIEF...   \n",
            "16    MLTDSGGGGTSFEEDLDSVAPRSAPAGASEPPPPGGVGLGIRTVRL...   \n",
            "17    MLTDSGGGGTSFEEDLDSVAPRSAPAGASEPPPPGGVGLGIRTVRL...   \n",
            "18    MLTDSGGGGTSFEEDLDSVAPRSAPAGASEPPPPGGVGLGIRTVRL...   \n",
            "19    MLTDSGGGGTSFEEDLDSVAPRSAPAGASEPPPPGGVGLGIRTVRL...   \n",
            "117   MGDVKNFLYAWCGKRKMTPSYEIRAVGNKNRQKFMCEVQVEGYNYT...   \n",
            "118   MGDVKNFLYAWCGKRKMTPSYEIRAVGNKNRQKFMCEVQVEGYNYT...   \n",
            "119   MGDVKNFLYAWCGKRKMTPSYEIRAVGNKNRQKFMCEVQVEGYNYT...   \n",
            "1409  MAARRGRRDGVAPPPSGGPGPDPGGGARGSGWGSRSQAPYGTLGAV...   \n",
            "1410  MAARRGRRDGVAPPPSGGPGPDPGGGARGSGWGSRSQAPYGTLGAV...   \n",
            "1411  MAARRGRRDGVAPPPSGGPGPDPGGGARGSGWGSRSQAPYGTLGAV...   \n",
            "1412  MAARRGRRDGVAPPPSGGPGPDPGGGARGSGWGSRSQAPYGTLGAV...   \n",
            "1413  MAARRGRRDGVAPPPSGGPGPDPGGGARGSGWGSRSQAPYGTLGAV...   \n",
            "1414  MAARRGRRDGVAPPPSGGPGPDPGGGARGSGWGSRSQAPYGTLGAV...   \n",
            "1415  MAARRGRRDGVAPPPSGGPGPDPGGGARGSGWGSRSQAPYGTLGAV...   \n",
            "1416  MAARRGRRDGVAPPPSGGPGPDPGGGARGSGWGSRSQAPYGTLGAV...   \n",
            "1539  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1540  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1541  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1542  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1543  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1544  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1545  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1546  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1547  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1548  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1549  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1550  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1551  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1552  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1553  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1554  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1555  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1556  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1557  MSVACVLKRKAVLWQDSFSPHLKHHPQEPANPNMPVVLTSGTGSQA...   \n",
            "1706  MWGDSRPANRTGPFRGSQEERFAPGWNRDYPPPPLKSHAQERHSGN...   \n",
            "1707  MWGDSRPANRTGPFRGSQEERFAPGWNRDYPPPPLKSHAQERHSGN...   \n",
            "1708  MWGDSRPANRTGPFRGSQEERFAPGWNRDYPPPPLKSHAQERHSGN...   \n",
            "1709  MWGDSRPANRTGPFRGSQEERFAPGWNRDYPPPPLKSHAQERHSGN...   \n",
            "1710  MWGDSRPANRTGPFRGSQEERFAPGWNRDYPPPPLKSHAQERHSGN...   \n",
            "1711  MWGDSRPANRTGPFRGSQEERFAPGWNRDYPPPPLKSHAQERHSGN...   \n",
            "1750  MPVQAPQWTDFLSCPICTQTFDETIRKPISLGCGHTVCKMCLNKLH...   \n",
            "1751  MPVQAPQWTDFLSCPICTQTFDETIRKPISLGCGHTVCKMCLNKLH...   \n",
            "1752  MPVQAPQWTDFLSCPICTQTFDETIRKPISLGCGHTVCKMCLNKLH...   \n",
            "2853  MAMDQVNALCEQLVKAVTVMMDPNSTQRYRLEALKFCEEFKEKCPI...   \n",
            "2854  MAMDQVNALCEQLVKAVTVMMDPNSTQRYRLEALKFCEEFKEKCPI...   \n",
            "3002  MSRPRFNPRGDFPLQRPRAPNPSGMRPPGPFMRPGSMGLPRFYPAG...   \n",
            "3003  MSRPRFNPRGDFPLQRPRAPNPSGMRPPGPFMRPGSMGLPRFYPAG...   \n",
            "3004  MSRPRFNPRGDFPLQRPRAPNPSGMRPPGPFMRPGSMGLPRFYPAG...   \n",
            "3005  MSRPRFNPRGDFPLQRPRAPNPSGMRPPGPFMRPGSMGLPRFYPAG...   \n",
            "3006  MSRPRFNPRGDFPLQRPRAPNPSGMRPPGPFMRPGSMGLPRFYPAG...   \n",
            "3007  MSRPRFNPRGDFPLQRPRAPNPSGMRPPGPFMRPGSMGLPRFYPAG...   \n",
            "3008  MSRPRFNPRGDFPLQRPRAPNPSGMRPPGPFMRPGSMGLPRFYPAG...   \n",
            "3009  MSRPRFNPRGDFPLQRPRAPNPSGMRPPGPFMRPGSMGLPRFYPAG...   \n",
            "3010  MSRPRFNPRGDFPLQRPRAPNPSGMRPPGPFMRPGSMGLPRFYPAG...   \n",
            "3011  MSRPRFNPRGDFPLQRPRAPNPSGMRPPGPFMRPGSMGLPRFYPAG...   \n",
            "3012  MSRPRFNPRGDFPLQRPRAPNPSGMRPPGPFMRPGSMGLPRFYPAG...   \n",
            "3013  MSRPRFNPRGDFPLQRPRAPNPSGMRPPGPFMRPGSMGLPRFYPAG...   \n",
            "\n",
            "                                          rna_motif_emb  \\\n",
            "9     [[0.08090142160654068, -0.19107750058174133, 2...   \n",
            "10    [[0.08060295134782791, -0.08036856353282928, 4...   \n",
            "16    [[0.04411252588033676, -0.07298469543457031, 4...   \n",
            "17    [[0.10889061540365219, -0.13527213037014008, 1...   \n",
            "18    [[0.03999633342027664, -0.056187186390161514, ...   \n",
            "19    [[0.0601712167263031, -0.07120835781097412, -5...   \n",
            "117   [[-0.008567733690142632, -0.14856842160224915,...   \n",
            "118   [[0.08090142160654068, -0.19107750058174133, 2...   \n",
            "119   [[0.08060295134782791, -0.08036856353282928, 4...   \n",
            "1409  [[0.044276319444179535, -0.12853433191776276, ...   \n",
            "1410  [[0.08522571623325348, -0.11117696762084961, 4...   \n",
            "1411  [[0.050339631736278534, -0.15988416969776154, ...   \n",
            "1412  [[0.11519031971693039, -0.1707472801208496, 3....   \n",
            "1413  [[0.09328223764896393, -0.11497247219085693, -...   \n",
            "1414  [[0.1300448775291443, -0.06248677149415016, 3....   \n",
            "1415  [[0.10673754662275314, -0.11756394803524017, -...   \n",
            "1416  [[0.08298107981681824, -0.1573147177696228, 4....   \n",
            "1539  [[0.10130055993795395, -0.13081854581832886, 5...   \n",
            "1540  [[0.05728580057621002, -0.22708117961883545, -...   \n",
            "1541  [[0.054938048124313354, -0.19068582355976105, ...   \n",
            "1542  [[0.013807035982608795, -0.16286584734916687, ...   \n",
            "1543  [[0.00019535236060619354, -0.1833554208278656,...   \n",
            "1544  [[0.038419805467128754, -0.17248831689357758, ...   \n",
            "1545  [[0.053832538425922394, -0.17467035353183746, ...   \n",
            "1546  [[0.13694548606872559, -0.1652558296918869, 2....   \n",
            "1547  [[0.005564678460359573, -0.12810859084129333, ...   \n",
            "1548  [[0.013807035982608795, -0.16286584734916687, ...   \n",
            "1549  [[0.023802541196346283, -0.13812479376792908, ...   \n",
            "1550  [[0.053832538425922394, -0.17467035353183746, ...   \n",
            "1551  [[0.013807035982608795, -0.16286584734916687, ...   \n",
            "1552  [[0.023802541196346283, -0.13812479376792908, ...   \n",
            "1553  [[0.053832538425922394, -0.17467035353183746, ...   \n",
            "1554  [[0.02169741317629814, -0.13193464279174805, 5...   \n",
            "1555  [[0.023802541196346283, -0.13812479376792908, ...   \n",
            "1556  [[0.05213456600904465, -0.1654738187789917, 1....   \n",
            "1557  [[0.06364807486534119, -0.13319182395935059, 1...   \n",
            "1706  [[0.017606783658266068, -0.05644745007157326, ...   \n",
            "1707  [[0.023882713168859482, -0.057770635932683945,...   \n",
            "1708  [[0.022488493472337723, -0.06467697024345398, ...   \n",
            "1709  [[0.02979019284248352, -0.06563252210617065, 3...   \n",
            "1710  [[0.0391518771648407, -0.12594087421894073, 1....   \n",
            "1711  [[0.03275352716445923, -0.15053333342075348, 2...   \n",
            "1750  [[0.12399657815694809, -0.2078547179698944, -3...   \n",
            "1751  [[0.17611777782440186, -0.15336914360523224, 8...   \n",
            "1752  [[-0.034418992698192596, -0.06963737308979034,...   \n",
            "2853  [[0.0557500496506691, -0.13185231387615204, -6...   \n",
            "2854  [[0.012973293662071228, -0.036773066967725754,...   \n",
            "3002  [[0.0136956125497818, -0.219100683927536, -6.1...   \n",
            "3003  [[0.003300335258245468, -0.15352565050125122, ...   \n",
            "3004  [[-0.020603429526090622, -0.09956203401088715,...   \n",
            "3005  [[0.03928819298744202, -0.2195887267589569, -4...   \n",
            "3006  [[0.0474453866481781, -0.20520251989364624, 3....   \n",
            "3007  [[0.03019539639353752, -0.14999355375766754, 3...   \n",
            "3008  [[0.13119709491729736, -0.22064316272735596, -...   \n",
            "3009  [[0.13698196411132812, -0.1633862406015396, 2....   \n",
            "3010  [[0.16278880834579468, -0.13394774496555328, 2...   \n",
            "3011  [[0.10849466174840927, -0.23209652304649353, -...   \n",
            "3012  [[0.05471719056367874, -0.24597996473312378, 7...   \n",
            "3013  [[0.06560936570167542, -0.1298510879278183, 4....   \n",
            "\n",
            "                                            rbp_esm_emb  sequence_length  \\\n",
            "9     [[0.19985901, -0.10205754, 0.12551533, 0.11393...             1226   \n",
            "10    [[0.19985901, -0.10205754, 0.12551533, 0.11393...             1226   \n",
            "16    [[0.0525801, -0.17387089, 0.051721334, 0.02062...             2542   \n",
            "17    [[0.0525801, -0.17387089, 0.051721334, 0.02062...             2542   \n",
            "18    [[0.0525801, -0.17387089, 0.051721334, 0.02062...             2542   \n",
            "19    [[0.0525801, -0.17387089, 0.051721334, 0.02062...             2542   \n",
            "117   [[0.106698625, -0.20897043, 0.036596503, 0.169...             1270   \n",
            "118   [[0.106698625, -0.20897043, 0.036596503, 0.169...             1270   \n",
            "119   [[0.106698625, -0.20897043, 0.036596503, 0.169...             1270   \n",
            "1409  [[-0.009681638, -0.08984677, 0.101789035, 0.07...             1664   \n",
            "1410  [[-0.009681638, -0.08984677, 0.101789035, 0.07...             1664   \n",
            "1411  [[-0.009681638, -0.08984677, 0.101789035, 0.07...             1664   \n",
            "1412  [[-0.009681638, -0.08984677, 0.101789035, 0.07...             1664   \n",
            "1413  [[-0.009681638, -0.08984677, 0.101789035, 0.07...             1664   \n",
            "1414  [[-0.009681638, -0.08984677, 0.101789035, 0.07...             1664   \n",
            "1415  [[-0.009681638, -0.08984677, 0.101789035, 0.07...             1664   \n",
            "1416  [[-0.009681638, -0.08984677, 0.101789035, 0.07...             1664   \n",
            "1539  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1540  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1541  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1542  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1543  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1544  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1545  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1546  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1547  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1548  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1549  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1550  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1551  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1552  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1553  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1554  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1555  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1556  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1557  [[0.04640395, -0.12407258, 0.042323772, -0.094...             1186   \n",
            "1706  [[0.17929795, -0.012491526, 0.1264204, 0.03477...             1123   \n",
            "1707  [[0.17929795, -0.012491526, 0.1264204, 0.03477...             1123   \n",
            "1708  [[0.17929795, -0.012491526, 0.1264204, 0.03477...             1123   \n",
            "1709  [[0.17929795, -0.012491526, 0.1264204, 0.03477...             1123   \n",
            "1710  [[0.17929795, -0.012491526, 0.1264204, 0.03477...             1123   \n",
            "1711  [[0.17929795, -0.012491526, 0.1264204, 0.03477...             1123   \n",
            "1750  [[0.15598926, -0.31563592, -0.3538424, 0.22616...             1133   \n",
            "1751  [[0.15598926, -0.31563592, -0.3538424, 0.22616...             1133   \n",
            "1752  [[0.15598926, -0.31563592, -0.3538424, 0.22616...             1133   \n",
            "2853  [[-0.02561606, 0.048216682, 0.05567033, 0.2323...             1204   \n",
            "2854  [[-0.02561606, 0.048216682, 0.05567033, 0.2323...             1204   \n",
            "3002  [[0.09905524, -0.039723452, 0.15728344, 0.0838...             1978   \n",
            "3003  [[0.09905524, -0.039723452, 0.15728344, 0.0838...             1978   \n",
            "3004  [[0.09905524, -0.039723452, 0.15728344, 0.0838...             1978   \n",
            "3005  [[0.09905524, -0.039723452, 0.15728344, 0.0838...             1978   \n",
            "3006  [[0.09905524, -0.039723452, 0.15728344, 0.0838...             1978   \n",
            "3007  [[0.09905524, -0.039723452, 0.15728344, 0.0838...             1978   \n",
            "3008  [[0.09905524, -0.039723452, 0.15728344, 0.0838...             1978   \n",
            "3009  [[0.09905524, -0.039723452, 0.15728344, 0.0838...             1978   \n",
            "3010  [[0.09905524, -0.039723452, 0.15728344, 0.0838...             1978   \n",
            "3011  [[0.09905524, -0.039723452, 0.15728344, 0.0838...             1978   \n",
            "3012  [[0.09905524, -0.039723452, 0.15728344, 0.0838...             1978   \n",
            "3013  [[0.09905524, -0.039723452, 0.15728344, 0.0838...             1978   \n",
            "\n",
            "      z_scores  \n",
            "9     3.541061  \n",
            "10    3.541061  \n",
            "16    9.290834  \n",
            "17    9.290834  \n",
            "18    9.290834  \n",
            "19    9.290834  \n",
            "117   3.733302  \n",
            "118   3.733302  \n",
            "119   3.733302  \n",
            "1409  5.454739  \n",
            "1410  5.454739  \n",
            "1411  5.454739  \n",
            "1412  5.454739  \n",
            "1413  5.454739  \n",
            "1414  5.454739  \n",
            "1415  5.454739  \n",
            "1416  5.454739  \n",
            "1539  3.366295  \n",
            "1540  3.366295  \n",
            "1541  3.366295  \n",
            "1542  3.366295  \n",
            "1543  3.366295  \n",
            "1544  3.366295  \n",
            "1545  3.366295  \n",
            "1546  3.366295  \n",
            "1547  3.366295  \n",
            "1548  3.366295  \n",
            "1549  3.366295  \n",
            "1550  3.366295  \n",
            "1551  3.366295  \n",
            "1552  3.366295  \n",
            "1553  3.366295  \n",
            "1554  3.366295  \n",
            "1555  3.366295  \n",
            "1556  3.366295  \n",
            "1557  3.366295  \n",
            "1706  3.091040  \n",
            "1707  3.091040  \n",
            "1708  3.091040  \n",
            "1709  3.091040  \n",
            "1710  3.091040  \n",
            "1711  3.091040  \n",
            "1750  3.134732  \n",
            "1751  3.134732  \n",
            "1752  3.134732  \n",
            "2853  3.444940  \n",
            "2854  3.444940  \n",
            "3002  6.826645  \n",
            "3003  6.826645  \n",
            "3004  6.826645  \n",
            "3005  6.826645  \n",
            "3006  6.826645  \n",
            "3007  6.826645  \n",
            "3008  6.826645  \n",
            "3009  6.826645  \n",
            "3010  6.826645  \n",
            "3011  6.826645  \n",
            "3012  6.826645  \n",
            "3013  6.826645  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_rbp_sequence_length = filtered_data['RBP_sequence'].apply(len).max()\n",
        "min_rbp_sequence_length = filtered_data['RBP_sequence'].apply(len).min()\n",
        "max_motif_length = filtered_data['Motif'].apply(len).max()\n",
        "min_motif_length = filtered_data['Motif'].apply(len).min()\n",
        "\n",
        "print(f\"Maximum RBP sequence length: {max_rbp_sequence_length}\")\n",
        "print(f\"Maximum Motif length: {max_motif_length}\")\n",
        "print(f\"Minimum RBP sequence length: {min_rbp_sequence_length}\")\n",
        "print(f\"Minimum Motif length: {min_motif_length}\")\n",
        "\n",
        "# Use these lengths for padding\n",
        "max_encoder_seq_length = max_motif_length\n",
        "max_decoder_seq_length = max_rbp_sequence_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amcb3YWRGCHp",
        "outputId": "0392096e-0c62-4f8f-c4a7-90aa1a1da7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum RBP sequence length: 1066\n",
            "Maximum Motif length: 12\n",
            "Minimum RBP sequence length: 136\n",
            "Minimum Motif length: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNLpP1fEsP0J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import ast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmBGN0NGMXm"
      },
      "source": [
        "### seq2seq model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCGFpkbWGkCG",
        "outputId": "9c778366-4718-4d9b-d14b-7c82c23d22b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Gene_name', 'Gene_id', 'Motif', 'RBP_sequence', 'rna_motif_emb',\n",
              "       'rbp_esm_emb', 'sequence_length', 'z_scores'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzeaWlnVGpf6",
        "outputId": "d3b834af-818d-4854-bc2a-1d4c3833a346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7, 120)\n",
            "(594, 1280)\n"
          ]
        }
      ],
      "source": [
        "print(data['rna_motif_emb'][1].shape)\n",
        "print(data['rbp_esm_emb'][1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = filtered_data.copy()"
      ],
      "metadata": {
        "id": "gRu3bA8ik8al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['sequence_length'].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaJAUdEPlI9p",
        "outputId": "b9c1a6e7-37f6-4682-ab45-4d77553235e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1066"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zev8fdq3H9ju",
        "outputId": "b0917e6d-a28b-48c1-db3a-55b6a271a606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Checking the GPU availability\n",
        "if not torch.cuda.is_available():\n",
        "    raise SystemError('GPU device not found')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fnq_UyHM87nZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAJx8JeD87na",
        "outputId": "e7694eef-0ad7-45bb-90ec-f94774f6900e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fair-esm\n",
            "Successfully installed fair-esm-2.0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ESM2(\n",
              "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
              "  (layers): ModuleList(\n",
              "    (0-32): 33 x TransformerLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (rot_emb): RotaryEmbedding()\n",
              "      )\n",
              "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
              "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (contact_head): ContactPredictionHead(\n",
              "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
              "    (activation): Sigmoid()\n",
              "  )\n",
              "  (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "  (lm_head): RobertaLMHead(\n",
              "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "!pip install fair-esm\n",
        "##setting up ESM\n",
        "import torch\n",
        "import esm\n",
        "esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "batch_converter = alphabet.get_batch_converter()\n",
        "esm_model.eval()  # disables dropout for deterministic results\n",
        "esm_model.cuda() #push model to gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPTAJozd8B9J"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "\n",
        "# 1. Dataset and DataLoader:\n",
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, encoder_data, decoder_data, decoder_target):\n",
        "        self.encoder_data = encoder_data\n",
        "        self.decoder_data = decoder_data\n",
        "        self.decoder_target = decoder_target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoder_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoder_data[idx], self.decoder_data[idx], self.decoder_target[idx]\n",
        "\n",
        "def pad_collate(batch):\n",
        "    (encoder_seqs, decoder_seqs, decoder_targets) = zip(*batch)\n",
        "\n",
        "    encoder_seqs_padded = torch.nn.utils.rnn.pad_sequence(encoder_seqs, batch_first=True, padding_value=0)\n",
        "    decoder_seqs_padded = torch.nn.utils.rnn.pad_sequence(decoder_seqs, batch_first=True, padding_value=0)\n",
        "    decoder_targets_padded = torch.nn.utils.rnn.pad_sequence(decoder_targets, batch_first=True, padding_value=0)\n",
        "\n",
        "    return encoder_seqs_padded, decoder_seqs_padded, decoder_targets_padded\n",
        "\n",
        "encoder_input_list = [torch.tensor(seq, dtype=torch.float32) for seq in data['rna_motif_emb'].tolist()]\n",
        "decoder_input_list = [torch.tensor(seq, dtype=torch.float32) for seq in data['rbp_esm_emb'].tolist()]\n",
        "decoder_target_list = [torch.tensor(np.roll(seq, shift=-1, axis=0), dtype=torch.float32) for seq in data['rbp_esm_emb'].tolist()]\n",
        "\n",
        "dataset = Seq2SeqDataset(encoder_input_list, decoder_input_list, decoder_target_list)\n",
        "\n",
        "# Splitting the dataset into training and test/validation sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# DataLoaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=pad_collate)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=pad_collate)\n",
        "\n",
        "# 2. Model Definition and Training Loop:\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments\n",
        "\n",
        "# The AdapterNetwork is the same as the previous code\n",
        "class AdapterNetwork(torch.nn.Module):\n",
        "    def __init__(self, output_size=1024):  # Remove the input_size from the initialization\n",
        "        super(AdapterNetwork, self).__init__()\n",
        "        self.fc = None  # Initialize the Linear layer as None\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Check if the Linear layer has been initialized\n",
        "        if self.fc is None:\n",
        "            # Dynamically compute the input size based on the shape of the input tensor\n",
        "            input_size = input.shape[-1]\n",
        "            self.fc = torch.nn.Linear(input_size, self.output_size).to(input.device)  # Ensure it's on the same device as the input\n",
        "\n",
        "        return self.fc(input)\n",
        "\n",
        "class CustomT5Model(T5ForConditionalGeneration):\n",
        "    def __init__(self, config, adapter_network):\n",
        "        super(CustomT5Model, self).__init__(config)\n",
        "        self.adapter_network = adapter_network\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        decoder_input_ids=None,\n",
        "        decoder_attention_mask=None,\n",
        "        rna_motif_emb=None,\n",
        "        **kwargs\n",
        "    ):\n",
        "        # Get the encoder outputs\n",
        "        encoder_outputs = self.encoder(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        # Here, we are using RNA motif embeddings directly instead of DNAModel\n",
        "        print(encoder_outputs[0].shape)\n",
        "        print(rna_motif_emb.shape)\n",
        "        joint_embedding = self.adapter_network(torch.cat((encoder_outputs[0], rna_motif_emb), dim=-1))\n",
        "\n",
        "        # Get the decoder outputs\n",
        "        decoder_outputs = self.decoder(\n",
        "            input_ids=decoder_input_ids,\n",
        "            attention_mask=decoder_attention_mask,\n",
        "            encoder_hidden_states=joint_embedding,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        lm_head_outputs = self.lm_head(decoder_outputs[0])\n",
        "\n",
        "        return lm_head_outputs\n",
        "\n",
        "# Initialize the adapter network\n",
        "# adapter_input_size = 120 + 1024  # Assuming the size of T5 encoder outputs is 1024\n",
        "# adapter_output_size = 1024  # The expected size for T5 decoder inputs\n",
        "# adapter_network = AdapterNetwork(adapter_input_size, adapter_output_size)\n",
        "\n",
        "\n",
        "adapter_output_size = 1024  # The expected size for T5 decoder inputs\n",
        "adapter_network = AdapterNetwork(adapter_output_size)\n",
        "\n",
        "\n",
        "# Initialize the custom T5 model\n",
        "model = CustomT5Model(config=T5ForConditionalGeneration.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc').config, adapter_network=adapter_network)\n",
        "\n",
        "# Now, you can use the model in the usual way with the provided train_dataloader and test_dataloader for training and evaluation.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "1ced33a0c4c047d097b624b1174dbcaa",
            "189c9dbfd3b1440188f78e1fbf8d7c95",
            "ca09ba179ce9409e857da5d08be9195f",
            "9c39d6e522534daba1710e753ccd928d",
            "8d8b99866a2e45f090b6a65bc73784d0",
            "c76ef859e9cf4517af41d24ca5952ac4",
            "1d016e2996bd48afb9b4a8ef8808aab7",
            "9abdfed93e05490292988b39bc10a9f8",
            "b928a6b46c5f43718d3d11144e5c0898",
            "0a87dde586b7420a9bd9e862299d0274",
            "6df6616a38ae49459e2db933f5852a5f",
            "ae4ceb887791451686e8c467180d1ae7",
            "44f004c71d7e44f0b837e0aeae56d7c6",
            "b5d68bb1e2de4dc8a85d78c21dbd6c4c",
            "d4bec0f187db499e8d238b98f376cd57",
            "7d430186c63b45f59686f338a1d51040",
            "742ea064c4f1447ca3b691a72f7090d7",
            "eef6e2d404074274a5cab350b7d6af3c",
            "f592c9c24d884c01ab5f16b9478ec0f9",
            "ccfcef64906b4e18bdc56ac2833222f4",
            "f72a29f6cfb94061b82a6e7901bca636",
            "c13987c2838a477ab426b920dc785d57"
          ]
        },
        "id": "MXuUUNHTCqp8",
        "outputId": "e92469c5-461a-4215-cb49-ed4dac5396bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/656 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ced33a0c4c047d097b624b1174dbcaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae4ceb887791451686e8c467180d1ae7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at Rostlab/prot_t5_xl_half_uniref50-enc and are newly initialized: ['decoder.block.20.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.2.layer_norm.weight', 'decoder.block.10.layer.2.layer_norm.weight', 'decoder.block.17.layer.0.SelfAttention.v.weight', 'decoder.block.20.layer.0.SelfAttention.o.weight', 'decoder.block.14.layer.0.SelfAttention.q.weight', 'decoder.block.21.layer.0.layer_norm.weight', 'decoder.block.1.layer.2.DenseReluDense.wi.weight', 'decoder.block.21.layer.2.DenseReluDense.wi.weight', 'decoder.block.6.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.o.weight', 'decoder.block.5.layer.1.EncDecAttention.o.weight', 'decoder.block.18.layer.2.layer_norm.weight', 'decoder.block.11.layer.1.EncDecAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'decoder.block.10.layer.1.EncDecAttention.k.weight', 'decoder.block.13.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.0.SelfAttention.k.weight', 'decoder.block.3.layer.1.EncDecAttention.o.weight', 'decoder.block.20.layer.1.EncDecAttention.v.weight', 'decoder.block.0.layer.2.DenseReluDense.wi.weight', 'decoder.block.18.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.0.SelfAttention.o.weight', 'decoder.block.21.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.k.weight', 'decoder.block.7.layer.0.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.v.weight', 'decoder.block.1.layer.1.EncDecAttention.q.weight', 'decoder.block.14.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.o.weight', 'decoder.block.16.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.2.layer_norm.weight', 'decoder.block.7.layer.2.layer_norm.weight', 'decoder.block.19.layer.0.SelfAttention.v.weight', 'decoder.block.2.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.1.layer_norm.weight', 'decoder.block.5.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.1.layer_norm.weight', 'decoder.block.4.layer.2.DenseReluDense.wo.weight', 'decoder.block.20.layer.0.layer_norm.weight', 'decoder.block.23.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.2.DenseReluDense.wo.weight', 'decoder.block.0.layer.2.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.1.EncDecAttention.o.weight', 'decoder.block.12.layer.0.SelfAttention.k.weight', 'decoder.block.8.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.1.layer_norm.weight', 'decoder.block.13.layer.1.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wo.weight', 'decoder.block.10.layer.0.SelfAttention.v.weight', 'decoder.block.18.layer.0.layer_norm.weight', 'decoder.block.6.layer.0.layer_norm.weight', 'decoder.block.12.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.o.weight', 'decoder.block.21.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.1.EncDecAttention.q.weight', 'decoder.block.13.layer.1.EncDecAttention.k.weight', 'decoder.block.11.layer.2.DenseReluDense.wi.weight', 'decoder.block.2.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.0.layer_norm.weight', 'decoder.block.13.layer.0.SelfAttention.q.weight', 'decoder.block.21.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.0.layer_norm.weight', 'decoder.block.9.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.2.layer_norm.weight', 'decoder.block.16.layer.0.SelfAttention.o.weight', 'decoder.block.14.layer.1.EncDecAttention.k.weight', 'decoder.block.21.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.v.weight', 'decoder.block.23.layer.2.DenseReluDense.wi.weight', 'decoder.block.20.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.1.layer_norm.weight', 'decoder.block.17.layer.0.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.1.EncDecAttention.v.weight', 'decoder.block.13.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.2.DenseReluDense.wo.weight', 'decoder.block.17.layer.0.SelfAttention.k.weight', 'decoder.block.19.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.1.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.v.weight', 'decoder.block.13.layer.1.EncDecAttention.q.weight', 'decoder.block.20.layer.0.SelfAttention.q.weight', 'decoder.block.10.layer.0.layer_norm.weight', 'decoder.block.15.layer.2.layer_norm.weight', 'decoder.block.23.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.2.layer_norm.weight', 'decoder.block.3.layer.2.DenseReluDense.wi.weight', 'decoder.block.8.layer.0.SelfAttention.k.weight', 'decoder.block.14.layer.1.EncDecAttention.o.weight', 'decoder.block.15.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.0.SelfAttention.v.weight', 'decoder.block.6.layer.2.DenseReluDense.wo.weight', 'decoder.block.5.layer.1.layer_norm.weight', 'decoder.block.4.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.2.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.1.EncDecAttention.v.weight', 'decoder.block.15.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.0.layer_norm.weight', 'decoder.block.19.layer.1.layer_norm.weight', 'decoder.block.2.layer.0.SelfAttention.k.weight', 'decoder.block.5.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.q.weight', 'decoder.block.16.layer.0.layer_norm.weight', 'decoder.block.21.layer.0.SelfAttention.v.weight', 'decoder.block.5.layer.1.EncDecAttention.q.weight', 'decoder.block.9.layer.2.layer_norm.weight', 'decoder.block.7.layer.2.DenseReluDense.wi.weight', 'decoder.block.0.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.2.layer_norm.weight', 'decoder.block.11.layer.0.layer_norm.weight', 'decoder.block.13.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.1.layer_norm.weight', 'decoder.block.23.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.layer_norm.weight', 'decoder.block.22.layer.0.SelfAttention.o.weight', 'decoder.block.17.layer.2.DenseReluDense.wi.weight', 'decoder.block.17.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.1.layer_norm.weight', 'decoder.block.23.layer.0.layer_norm.weight', 'decoder.block.22.layer.0.SelfAttention.q.weight', 'decoder.block.9.layer.0.SelfAttention.v.weight', 'decoder.block.15.layer.0.layer_norm.weight', 'decoder.block.19.layer.1.EncDecAttention.o.weight', 'decoder.block.22.layer.2.DenseReluDense.wo.weight', 'decoder.block.1.layer.1.EncDecAttention.v.weight', 'decoder.block.16.layer.1.EncDecAttention.k.weight', 'decoder.block.16.layer.2.DenseReluDense.wi.weight', 'decoder.block.12.layer.2.DenseReluDense.wi.weight', 'decoder.block.23.layer.2.DenseReluDense.wo.weight', 'decoder.block.12.layer.1.EncDecAttention.o.weight', 'decoder.block.23.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.0.SelfAttention.v.weight', 'decoder.block.0.layer.0.layer_norm.weight', 'decoder.block.16.layer.0.SelfAttention.q.weight', 'decoder.block.21.layer.1.layer_norm.weight', 'decoder.block.5.layer.1.EncDecAttention.k.weight', 'decoder.block.20.layer.1.EncDecAttention.q.weight', 'decoder.block.0.layer.0.SelfAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.2.DenseReluDense.wo.weight', 'decoder.block.13.layer.2.DenseReluDense.wo.weight', 'decoder.block.9.layer.0.layer_norm.weight', 'decoder.block.18.layer.2.DenseReluDense.wi.weight', 'decoder.block.7.layer.0.SelfAttention.v.weight', 'decoder.block.12.layer.1.EncDecAttention.q.weight', 'decoder.block.10.layer.0.SelfAttention.q.weight', 'decoder.block.19.layer.2.layer_norm.weight', 'decoder.block.4.layer.0.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.k.weight', 'decoder.block.13.layer.0.layer_norm.weight', 'decoder.block.18.layer.1.EncDecAttention.q.weight', 'decoder.block.3.layer.1.EncDecAttention.k.weight', 'decoder.block.22.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.0.SelfAttention.k.weight', 'decoder.block.11.layer.1.EncDecAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.1.EncDecAttention.k.weight', 'decoder.block.6.layer.1.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.v.weight', 'decoder.block.16.layer.2.layer_norm.weight', 'decoder.block.11.layer.0.SelfAttention.k.weight', 'decoder.block.23.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.0.SelfAttention.v.weight', 'decoder.block.10.layer.0.SelfAttention.o.weight', 'decoder.block.17.layer.2.DenseReluDense.wo.weight', 'decoder.final_layer_norm.weight', 'decoder.block.23.layer.0.SelfAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.k.weight', 'decoder.block.15.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.layer_norm.weight', 'decoder.block.0.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.1.layer_norm.weight', 'decoder.block.23.layer.1.layer_norm.weight', 'decoder.block.0.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.v.weight', 'decoder.block.5.layer.0.layer_norm.weight', 'decoder.block.2.layer.1.EncDecAttention.o.weight', 'decoder.block.13.layer.0.SelfAttention.o.weight', 'decoder.block.1.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.2.DenseReluDense.wo.weight', 'decoder.block.8.layer.0.SelfAttention.q.weight', 'decoder.block.15.layer.1.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.v.weight', 'decoder.block.4.layer.0.SelfAttention.o.weight', 'decoder.block.12.layer.1.EncDecAttention.k.weight', 'decoder.block.12.layer.0.SelfAttention.o.weight', 'decoder.block.16.layer.1.layer_norm.weight', 'decoder.block.19.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.0.SelfAttention.v.weight', 'decoder.block.7.layer.1.EncDecAttention.k.weight', 'decoder.block.4.layer.1.EncDecAttention.v.weight', 'decoder.block.14.layer.0.SelfAttention.o.weight', 'decoder.block.15.layer.1.EncDecAttention.k.weight', 'decoder.block.8.layer.0.SelfAttention.o.weight', 'decoder.block.18.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.1.EncDecAttention.q.weight', 'decoder.block.16.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.q.weight', 'decoder.block.17.layer.1.layer_norm.weight', 'decoder.block.1.layer.0.SelfAttention.q.weight', 'decoder.block.7.layer.0.SelfAttention.q.weight', 'decoder.block.11.layer.0.SelfAttention.o.weight', 'decoder.block.7.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.2.DenseReluDense.wo.weight', 'decoder.block.15.layer.1.EncDecAttention.o.weight', 'decoder.block.14.layer.0.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.k.weight', 'decoder.block.20.layer.1.EncDecAttention.k.weight', 'decoder.block.2.layer.2.DenseReluDense.wo.weight', 'decoder.block.22.layer.2.DenseReluDense.wi.weight', 'decoder.block.5.layer.2.layer_norm.weight', 'decoder.block.18.layer.0.SelfAttention.v.weight', 'decoder.block.12.layer.2.DenseReluDense.wo.weight', 'decoder.block.21.layer.1.EncDecAttention.q.weight', 'decoder.block.1.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.o.weight', 'decoder.block.21.layer.1.EncDecAttention.v.weight', 'decoder.block.20.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.2.layer_norm.weight', 'decoder.block.5.layer.0.SelfAttention.o.weight', 'decoder.block.8.layer.2.DenseReluDense.wo.weight', 'decoder.block.14.layer.2.DenseReluDense.wi.weight', 'decoder.block.16.layer.1.EncDecAttention.q.weight', 'decoder.block.6.layer.0.SelfAttention.q.weight', 'decoder.block.5.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.2.layer_norm.weight', 'decoder.block.3.layer.0.layer_norm.weight', 'decoder.block.23.layer.2.layer_norm.weight', 'decoder.block.2.layer.2.layer_norm.weight', 'decoder.block.14.layer.2.layer_norm.weight', 'decoder.block.21.layer.1.EncDecAttention.k.weight', 'decoder.block.23.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.1.EncDecAttention.v.weight', 'decoder.block.6.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.1.layer_norm.weight', 'decoder.block.3.layer.0.SelfAttention.v.weight', 'decoder.block.1.layer.0.SelfAttention.o.weight', 'decoder.block.22.layer.0.SelfAttention.k.weight', 'decoder.block.0.layer.0.SelfAttention.o.weight', 'decoder.block.0.layer.1.layer_norm.weight', 'decoder.block.10.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.1.EncDecAttention.k.weight', 'decoder.block.3.layer.2.layer_norm.weight', 'decoder.block.17.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.1.layer_norm.weight', 'decoder.block.3.layer.1.EncDecAttention.q.weight', 'decoder.block.19.layer.2.DenseReluDense.wi.weight', 'decoder.block.15.layer.0.SelfAttention.k.weight', 'decoder.block.2.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.1.layer_norm.weight', 'decoder.block.11.layer.2.layer_norm.weight', 'decoder.block.13.layer.1.EncDecAttention.o.weight', 'decoder.block.2.layer.1.EncDecAttention.v.weight', 'decoder.block.18.layer.2.DenseReluDense.wo.weight', 'decoder.block.7.layer.0.SelfAttention.o.weight', 'decoder.block.10.layer.1.EncDecAttention.o.weight', 'decoder.block.6.layer.1.EncDecAttention.k.weight', 'decoder.block.9.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.1.EncDecAttention.v.weight', 'decoder.block.17.layer.0.SelfAttention.q.weight', 'decoder.block.1.layer.0.SelfAttention.k.weight', 'decoder.block.10.layer.1.EncDecAttention.q.weight', 'decoder.block.4.layer.1.EncDecAttention.q.weight', 'decoder.block.18.layer.0.SelfAttention.q.weight', 'decoder.block.8.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.0.SelfAttention.v.weight', 'decoder.block.14.layer.0.SelfAttention.k.weight', 'decoder.block.6.layer.0.SelfAttention.k.weight', 'decoder.block.12.layer.1.layer_norm.weight', 'decoder.block.7.layer.1.EncDecAttention.v.weight', 'decoder.block.9.layer.1.layer_norm.weight', 'decoder.block.0.layer.1.EncDecAttention.q.weight', 'decoder.block.12.layer.0.SelfAttention.q.weight', 'decoder.block.3.layer.2.DenseReluDense.wo.weight', 'decoder.block.6.layer.0.SelfAttention.o.weight', 'decoder.block.19.layer.0.SelfAttention.q.weight', 'decoder.block.4.layer.0.SelfAttention.k.weight', 'decoder.block.15.layer.2.DenseReluDense.wi.weight', 'decoder.block.22.layer.1.EncDecAttention.o.weight', 'decoder.block.11.layer.1.EncDecAttention.q.weight', 'decoder.block.2.layer.0.layer_norm.weight', 'decoder.block.6.layer.1.EncDecAttention.v.weight', 'decoder.block.22.layer.0.layer_norm.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_list[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qefB282FTWGZ",
        "outputId": "a36bbd52-dd78-47c1-e39e-2b0c789730f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 120])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataloader.dataset"
      ],
      "metadata": {
        "id": "VeyNaOLiT6-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataset[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxJ3XuLDVEdv",
        "outputId": "2b0bcec6-818c-43ad-c479-abb83f942997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rna_motif_emb[11].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hODDGCx0GR5c",
        "outputId": "6fb33756-8ccc-406e-d88e-95c177f88dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 120)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "x52vRrKbIIY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Number of training epochs\n",
        "n_epochs = 3\n",
        "\n",
        "# Move the model to the appropriate device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Lists to store losses for plotting\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
        "\n",
        "    # Training\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    current_index = 0\n",
        "\n",
        "    for encoder_data, decoder_input, decoder_target in train_dataloader:\n",
        "        batch_size = encoder_data.size(0)\n",
        "        batch_rna_motif_emb = rna_motif_emb[current_index:current_index + batch_size]\n",
        "        current_index += batch_size\n",
        "\n",
        "        max_length = max(len(item) for item in batch_rna_motif_emb)\n",
        "        padded_rna_motif_emb = np.array(\n",
        "            [np.pad(item, ((0, max_length - len(item)), (0, 0)), 'constant', constant_values=0)\n",
        "             for item in batch_rna_motif_emb],\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # Move data to device\n",
        "        encoder_data = encoder_data.to(device)\n",
        "        decoder_input = decoder_input.to(device)\n",
        "        decoder_target = decoder_target.to(device)\n",
        "\n",
        "        # Prepare rna_motif_emb_tensor and ensure it's on the same device as encoder_data\n",
        "        rna_motif_emb_tensor = torch.from_numpy(padded_rna_motif_emb).to(device)\n",
        "\n",
        "        joint_embedding = torch.cat((encoder_data, rna_motif_emb_tensor), dim=1)\n",
        "        print(joint_embedding.shape)\n",
        "        joint_embedding_flattened = joint_embedding.view(joint_embedding.size(0), -1)\n",
        "        print(joint_embedding_flattened.shape)\n",
        "        encoder_data_transformed = adapter_network(joint_embedding_flattened)\n",
        "        print(encoder_data_transformed)\n",
        "        outputs = model(inputs_embeds=encoder_data_transformed,\n",
        "                        attention_mask=None,\n",
        "                        decoder_input_ids=decoder_input)\n",
        "\n",
        "        loss = criterion(outputs.view(-1, outputs.size(-1)), decoder_target.view(-1))\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    average_train_loss = total_loss / len(train_dataloader)\n",
        "    train_losses.append(average_train_loss)\n",
        "    print(f\"Training loss: {average_train_loss}\")\n",
        "\n",
        "    # Evaluation on test data\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for encoder_data, decoder_input, decoder_target in test_dataloader:\n",
        "            encoder_data = encoder_data.to(device)\n",
        "            decoder_input = decoder_input.to(device)\n",
        "            decoder_target = decoder_target.to(device)\n",
        "\n",
        "            encoder_data_transformed = adapter_network(encoder_data)\n",
        "            outputs = model(input_ids=encoder_data_transformed,\n",
        "                            attention_mask=None,\n",
        "                            decoder_input_ids=decoder_input)\n",
        "\n",
        "            loss = criterion(outputs.view(-1, outputs.size(-1)), decoder_target.view(-1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    average_test_loss = total_loss / len(test_dataloader)\n",
        "    test_losses.append(average_test_loss)\n",
        "    print(f\"Validation loss: {average_test_loss}\")\n",
        "\n",
        "# Plot the training and validation losses\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(test_losses, label='Validation Loss')\n",
        "plt.title('Training and Validation Losses over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "ka1Ipb1OD__8",
        "outputId": "1dede330-75d6-4412-9bfe-52a033d15f39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "torch.Size([4, 20, 120])\n",
            "torch.Size([4, 2400])\n",
            "tensor([[ 0.0523, -0.1181,  0.0028,  ...,  0.0648, -0.0117, -0.0824],\n",
            "        [-0.0317, -0.0724, -0.0091,  ...,  0.0167,  0.0228,  0.0039],\n",
            "        [-0.0215, -0.0459,  0.0064,  ...,  0.0806,  0.0582, -0.0232],\n",
            "        [-0.0764, -0.0665, -0.0339,  ...,  0.0605, -0.0028, -0.0394]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-92e8d91414b6>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mencoder_data_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoint_embedding_flattened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_data_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         outputs = model(inputs_embeds=encoder_data_transformed,\n\u001b[0m\u001b[1;32m     53\u001b[0m                         \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                         decoder_input_ids=decoder_input)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-59298188454b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, rna_motif_emb, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m     ):\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Get the encoder outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/modeling_t5.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;31m# required mask seq length can be calculated via length of past\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_data_transformed.shape"
      ],
      "metadata": {
        "id": "PSbWzDNPqQC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_data.shape"
      ],
      "metadata": {
        "id": "C6VzJzXQKbdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " rna_motif_emb_tensor.shape"
      ],
      "metadata": {
        "id": "DIewwCWHKf5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joint_embedding.shape"
      ],
      "metadata": {
        "id": "P_AXrWw4KqyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rna_motif_emb.shape"
      ],
      "metadata": {
        "id": "TsMZ7p5j3ykZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TNV6t61JGfZv"
      ],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1ced33a0c4c047d097b624b1174dbcaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_189c9dbfd3b1440188f78e1fbf8d7c95",
              "IPY_MODEL_ca09ba179ce9409e857da5d08be9195f",
              "IPY_MODEL_9c39d6e522534daba1710e753ccd928d"
            ],
            "layout": "IPY_MODEL_8d8b99866a2e45f090b6a65bc73784d0"
          }
        },
        "189c9dbfd3b1440188f78e1fbf8d7c95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c76ef859e9cf4517af41d24ca5952ac4",
            "placeholder": "​",
            "style": "IPY_MODEL_1d016e2996bd48afb9b4a8ef8808aab7",
            "value": "config.json: 100%"
          }
        },
        "ca09ba179ce9409e857da5d08be9195f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9abdfed93e05490292988b39bc10a9f8",
            "max": 656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b928a6b46c5f43718d3d11144e5c0898",
            "value": 656
          }
        },
        "9c39d6e522534daba1710e753ccd928d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a87dde586b7420a9bd9e862299d0274",
            "placeholder": "​",
            "style": "IPY_MODEL_6df6616a38ae49459e2db933f5852a5f",
            "value": " 656/656 [00:00&lt;00:00, 46.4kB/s]"
          }
        },
        "8d8b99866a2e45f090b6a65bc73784d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c76ef859e9cf4517af41d24ca5952ac4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d016e2996bd48afb9b4a8ef8808aab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9abdfed93e05490292988b39bc10a9f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b928a6b46c5f43718d3d11144e5c0898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a87dde586b7420a9bd9e862299d0274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6df6616a38ae49459e2db933f5852a5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae4ceb887791451686e8c467180d1ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44f004c71d7e44f0b837e0aeae56d7c6",
              "IPY_MODEL_b5d68bb1e2de4dc8a85d78c21dbd6c4c",
              "IPY_MODEL_d4bec0f187db499e8d238b98f376cd57"
            ],
            "layout": "IPY_MODEL_7d430186c63b45f59686f338a1d51040"
          }
        },
        "44f004c71d7e44f0b837e0aeae56d7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_742ea064c4f1447ca3b691a72f7090d7",
            "placeholder": "​",
            "style": "IPY_MODEL_eef6e2d404074274a5cab350b7d6af3c",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "b5d68bb1e2de4dc8a85d78c21dbd6c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f592c9c24d884c01ab5f16b9478ec0f9",
            "max": 2416373051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ccfcef64906b4e18bdc56ac2833222f4",
            "value": 2416373051
          }
        },
        "d4bec0f187db499e8d238b98f376cd57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f72a29f6cfb94061b82a6e7901bca636",
            "placeholder": "​",
            "style": "IPY_MODEL_c13987c2838a477ab426b920dc785d57",
            "value": " 2.42G/2.42G [00:07&lt;00:00, 341MB/s]"
          }
        },
        "7d430186c63b45f59686f338a1d51040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "742ea064c4f1447ca3b691a72f7090d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef6e2d404074274a5cab350b7d6af3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f592c9c24d884c01ab5f16b9478ec0f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccfcef64906b4e18bdc56ac2833222f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f72a29f6cfb94061b82a6e7901bca636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c13987c2838a477ab426b920dc785d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}