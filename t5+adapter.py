# -*- coding: utf-8 -*-
"""t5+adapter

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hdy3yJTlhR_DYl0Z1d-QIJ0B73ii-m53

with adapter + t5 decoder

### mount gdrive
"""

from google.colab import drive
drive.mount('/content/drive')

import os

os.chdir('/content/drive/MyDrive/rna-binding')

!pip install transformers

"""### data prep"""

import pandas as pd

data = pd.read_csv('final_attract_db_with_emb.csv')

import pickle
# Load the dictionary back from the pickle file.
with open("rbp_seqs_dict.pkl", "rb") as f:
    rbp_seqs_dict = pickle.load(f)

import numpy as np
rna_motif_emb = np.load('rna_motif_emb.npy', allow_pickle=True)

len(rna_motif_emb[1])

data = data.drop(columns=['rna_motif_emb', 'rbp_esm_emb'])

data['rna_motif_emb'] = rna_motif_emb

data['rbp_esm_emb'] = data['RBP_sequence'].map(rbp_seqs_dict)

# Convert list of tensors to numpy array
def tensors_to_numpy(tensor_list):
    return np.stack([t.numpy() for t in tensor_list])

# Apply the conversion to the 'rbp_esm_emb' column
data['rbp_esm_emb'] = data['rbp_esm_emb'].apply(tensors_to_numpy)

data

average_length = data['RBP_sequence'].apply(len).mean()
print(f"Average length of RBP_sequence: {average_length}")

# data = data[data['RBP_sequence'].apply(len) <= 600]

average_length = data['RBP_sequence'].apply(len).mean()
print(f"Average length of RBP_sequence: {average_length}")

max_rbp_sequence_length = data['RBP_sequence'].apply(len).max()
max_motif_length = data['Motif'].apply(len).max()

print(f"Maximum RBP sequence length: {max_rbp_sequence_length}")
print(f"Maximum Motif length: {max_motif_length}")

# Use these lengths for padding
max_encoder_seq_length = max_motif_length
max_decoder_seq_length = max_rbp_sequence_length

import pandas as pd
from scipy import stats

# Assuming meta4k is a DataFrame and 'sequence' is the column with sequence strings
# Calculate sequence lengths
data['sequence_length'] = data['RBP_sequence'].apply(len)

# Compute Z-scores of the lengths
data['z_scores'] = stats.zscore(data['sequence_length'])

# Filter the outliers; this will keep only the rows that are not outliers
filtered_data = data[(data['z_scores'] > -3) & (data['z_scores'] < 3)]

# Determine the outliers
outliers = data[(data['z_scores'] <= -3) | (data['z_scores'] >= 3)]

# Print the outliers
print(outliers)

max_rbp_sequence_length = filtered_data['RBP_sequence'].apply(len).max()
min_rbp_sequence_length = filtered_data['RBP_sequence'].apply(len).min()
max_motif_length = filtered_data['Motif'].apply(len).max()
min_motif_length = filtered_data['Motif'].apply(len).min()

print(f"Maximum RBP sequence length: {max_rbp_sequence_length}")
print(f"Maximum Motif length: {max_motif_length}")
print(f"Minimum RBP sequence length: {min_rbp_sequence_length}")
print(f"Minimum Motif length: {min_motif_length}")

# Use these lengths for padding
max_encoder_seq_length = max_motif_length
max_decoder_seq_length = max_rbp_sequence_length

import numpy as np
import ast

"""### seq2seq model"""

data.columns

print(data['rna_motif_emb'][1].shape)
print(data['rbp_esm_emb'][1].shape)

data = filtered_data.copy()

data['sequence_length'].max()

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Checking the GPU availability
if not torch.cuda.is_available():
    raise SystemError('GPU device not found')
print(f"Using device: {device}")

import pandas as pd
from tqdm import tqdm

!pip install fair-esm
##setting up ESM
import torch
import esm
esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()
batch_converter = alphabet.get_batch_converter()
esm_model.eval()  # disables dropout for deterministic results
esm_model.cuda() #push model to gpu

import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, random_split

# 1. Dataset and DataLoader:
class Seq2SeqDataset(Dataset):
    def __init__(self, encoder_data, decoder_data, decoder_target):
        self.encoder_data = encoder_data
        self.decoder_data = decoder_data
        self.decoder_target = decoder_target

    def __len__(self):
        return len(self.encoder_data)

    def __getitem__(self, idx):
        return self.encoder_data[idx], self.decoder_data[idx], self.decoder_target[idx]

def pad_collate(batch):
    (encoder_seqs, decoder_seqs, decoder_targets) = zip(*batch)

    encoder_seqs_padded = torch.nn.utils.rnn.pad_sequence(encoder_seqs, batch_first=True, padding_value=0)
    decoder_seqs_padded = torch.nn.utils.rnn.pad_sequence(decoder_seqs, batch_first=True, padding_value=0)
    decoder_targets_padded = torch.nn.utils.rnn.pad_sequence(decoder_targets, batch_first=True, padding_value=0)

    return encoder_seqs_padded, decoder_seqs_padded, decoder_targets_padded

encoder_input_list = [torch.tensor(seq, dtype=torch.float32) for seq in data['rna_motif_emb'].tolist()]
decoder_input_list = [torch.tensor(seq, dtype=torch.float32) for seq in data['rbp_esm_emb'].tolist()]
decoder_target_list = [torch.tensor(np.roll(seq, shift=-1, axis=0), dtype=torch.float32) for seq in data['rbp_esm_emb'].tolist()]

dataset = Seq2SeqDataset(encoder_input_list, decoder_input_list, decoder_target_list)

# Splitting the dataset into training and test/validation sets
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

# DataLoaders
train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=pad_collate)
test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, collate_fn=pad_collate)

# 2. Model Definition and Training Loop:
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

from transformers import T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments

# The AdapterNetwork is the same as the previous code
class AdapterNetwork(torch.nn.Module):
    def __init__(self, output_size=1024):  # Remove the input_size from the initialization
        super(AdapterNetwork, self).__init__()
        self.fc = None  # Initialize the Linear layer as None
        self.output_size = output_size

    def forward(self, input):
        # Check if the Linear layer has been initialized
        if self.fc is None:
            # Dynamically compute the input size based on the shape of the input tensor
            input_size = input.shape[-1]
            self.fc = torch.nn.Linear(input_size, self.output_size).to(input.device)  # Ensure it's on the same device as the input

        return self.fc(input)

class CustomT5Model(T5ForConditionalGeneration):
    def __init__(self, config, adapter_network):
        super(CustomT5Model, self).__init__(config)
        self.adapter_network = adapter_network

    def forward(
        self,
        input_ids=None,
        attention_mask=None,
        decoder_input_ids=None,
        decoder_attention_mask=None,
        rna_motif_emb=None,
        **kwargs
    ):
        # Get the encoder outputs
        encoder_outputs = self.encoder(
            input_ids=input_ids,
            attention_mask=attention_mask,
            **kwargs
        )

        # Here, we are using RNA motif embeddings directly instead of DNAModel
        print(encoder_outputs[0].shape)
        print(rna_motif_emb.shape)
        joint_embedding = self.adapter_network(torch.cat((encoder_outputs[0], rna_motif_emb), dim=-1))

        # Get the decoder outputs
        decoder_outputs = self.decoder(
            input_ids=decoder_input_ids,
            attention_mask=decoder_attention_mask,
            encoder_hidden_states=joint_embedding,
            **kwargs
        )

        lm_head_outputs = self.lm_head(decoder_outputs[0])

        return lm_head_outputs

# Initialize the adapter network
# adapter_input_size = 120 + 1024  # Assuming the size of T5 encoder outputs is 1024
# adapter_output_size = 1024  # The expected size for T5 decoder inputs
# adapter_network = AdapterNetwork(adapter_input_size, adapter_output_size)


adapter_output_size = 1024  # The expected size for T5 decoder inputs
adapter_network = AdapterNetwork(adapter_output_size)


# Initialize the custom T5 model
model = CustomT5Model(config=T5ForConditionalGeneration.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc').config, adapter_network=adapter_network)

# Now, you can use the model in the usual way with the provided train_dataloader and test_dataloader for training and evaluation.

encoder_input_list[0].shape

train_dataset = train_dataloader.dataset

len(train_dataset[1])

rna_motif_emb[11].shape

import numpy as np
import torch
import matplotlib.pyplot as plt

# Loss function
criterion = torch.nn.CrossEntropyLoss()

# Optimizer
optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)

# Number of training epochs
n_epochs = 3

# Move the model to the appropriate device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model.to(device)

# Lists to store losses for plotting
train_losses = []
test_losses = []

for epoch in range(n_epochs):
    print(f"Epoch {epoch + 1}/{n_epochs}")

    # Training
    model.train()
    total_loss = 0
    current_index = 0

    for encoder_data, decoder_input, decoder_target in train_dataloader:
        batch_size = encoder_data.size(0)
        batch_rna_motif_emb = rna_motif_emb[current_index:current_index + batch_size]
        current_index += batch_size

        max_length = max(len(item) for item in batch_rna_motif_emb)
        padded_rna_motif_emb = np.array(
            [np.pad(item, ((0, max_length - len(item)), (0, 0)), 'constant', constant_values=0)
             for item in batch_rna_motif_emb],
            dtype=np.float32
        )

        # Move data to device
        encoder_data = encoder_data.to(device)
        decoder_input = decoder_input.to(device)
        decoder_target = decoder_target.to(device)

        # Prepare rna_motif_emb_tensor and ensure it's on the same device as encoder_data
        rna_motif_emb_tensor = torch.from_numpy(padded_rna_motif_emb).to(device)

        joint_embedding = torch.cat((encoder_data, rna_motif_emb_tensor), dim=1)
        print(joint_embedding.shape)
        joint_embedding_flattened = joint_embedding.view(joint_embedding.size(0), -1)
        print(joint_embedding_flattened.shape)
        encoder_data_transformed = adapter_network(joint_embedding_flattened)
        print(encoder_data_transformed)
        outputs = model(inputs_embeds=encoder_data_transformed,
                        attention_mask=None,
                        decoder_input_ids=decoder_input)

        loss = criterion(outputs.view(-1, outputs.size(-1)), decoder_target.view(-1))
        total_loss += loss.item()

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    average_train_loss = total_loss / len(train_dataloader)
    train_losses.append(average_train_loss)
    print(f"Training loss: {average_train_loss}")

    # Evaluation on test data
    model.eval()
    total_loss = 0
    with torch.no_grad():
        for encoder_data, decoder_input, decoder_target in test_dataloader:
            encoder_data = encoder_data.to(device)
            decoder_input = decoder_input.to(device)
            decoder_target = decoder_target.to(device)

            encoder_data_transformed = adapter_network(encoder_data)
            outputs = model(input_ids=encoder_data_transformed,
                            attention_mask=None,
                            decoder_input_ids=decoder_input)

            loss = criterion(outputs.view(-1, outputs.size(-1)), decoder_target.view(-1))
            total_loss += loss.item()

    average_test_loss = total_loss / len(test_dataloader)
    test_losses.append(average_test_loss)
    print(f"Validation loss: {average_test_loss}")

# Plot the training and validation losses
plt.figure(figsize=(10, 5))
plt.plot(train_losses, label='Training Loss')
plt.plot(test_losses, label='Validation Loss')
plt.title('Training and Validation Losses over Epochs')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

encoder_data_transformed.shape

encoder_data.shape

rna_motif_emb_tensor.shape

joint_embedding.shape

rna_motif_emb.shape